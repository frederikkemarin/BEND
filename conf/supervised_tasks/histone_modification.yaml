defaults:
  - datadims : [label_dims,embedding_dims, downstream_downsample]
  - hydra : multirun 
  - misc : resnet_supervised
  - override hydra/launcher: joblib # ability to launch jobs in parallel fashion
  - _self_
hydra :
  searchpath:
    - file://conf 
  sweeper:
    params:
      embedder : gena-lm-bigbird-base-t2t,
                 gena-lm-bert-large-t2,
                 hyenadna-tiny-1k,
                 hyenadna-small-32k,
                 hyenadna-medium-160k,
                 hyenadna-medium-450k,
                 hyenadna-large-1m,
                 dnabert6,
                 resnetlm,
                 nt_transformer_ms,
                 nt_transformer_human_ref,
                 nt_transformer_1000g,
                 dnabert2,
                 onehot,
                 awdlstm,
                 resnet-supervised
embedder : onehot
task : histone_modification 
output_dir: ./downstream_tasks/${task}/${embedder}/
model:
  _target_: bend.models.downstream.CNN
  input_size: ${datadims.${embedder}}
  output_size: ${datadims.${task}}
  hidden_size: 64
  kernel_size: 3
  output_downsample_window : 512
optimizer : 
  _target_ : torch.optim.AdamW 
  lr : 0.003
  weight_decay: 0.01
data:
  _target_: bend.utils.data_downstream.get_data
  data_dir : ./data/${task}/${embedder}/
  cross_validation : false
  batch_size : 256
  num_workers : 0
  padding_value : -100
  shuffle : 200
  train_data : [train.tfrecord]
  valid_data : [valid.tfrecord]
  test_data :  [test.tfrecord]
params:
  epochs: 100
  load_checkpoint: true
  mode: train
  gradient_accumulation_steps: 1
  criterion: bce
  class_weights: null
  metric : auroc
  activation : none
wandb:
  mode : disabled 


